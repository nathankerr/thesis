\chapter{RELATED WORK}

\section{Desktop GIS}

\textbf{ArcInfo, QuantumGIS, GRASS GIS}

Desktop GIS packages such as ArcGIS\cite{arcgis}, QuantumGIS\cite{qgis},
and GRASS GIS\cite{grass} are commonly used for GIS processing and
analysis. While these programs provide graphical interfaces to their
GIS capabilities, their capabilities are limited by the computers they
run on.  Datasets can be too large for their memories and computations
can take too long to be practical. The popular simulation package,
UrbanSim\cite{urbansim} faces these same constraints.

\section{Database GIS}

\textbf{PostGIS, Oracle Spatial, Client-Server Paradise}

An alternative approach to using these desktop programs is to employ
a geospatial database like PostGIS\cite{postgis}, ArcSDE\cite{arcsde}
or Oracle Spatial\cite{oracle}. Geospatial databases allow centralized
access to, and processing of, geospatial data through query languages
such as SQL. As data is stored and managed by the database software,
advanced database features such as indexes can be utilized to speedup
data access and processing.

PostGIS is utilized as the core component of the Urban
Systems Frame-work\cite{usf} (USF) designed by the Digital
Phoenix\cite{digitalphoenix} project group at Arizona State
University. Digital Phoenix tries to integrate 3D visualization technology
with simulated and gathered GIS data to better understand the impacts
of urban planning decisions.

\section{GIS libraries}

\textbf{JTS, GEOS}

\section{Parallel DB}

One method of using multiple computers to perform the required
processing is the use of parallel databases\cite{hpdb}. Parallel
databases should be able to spread both data storage and
processing across multiple computers transparently from the view
of the SQL query programmer. Several commercial databases such as
TeraData\cite{teradata} and Oracle\cite{oracle} provide support for this
method of operation. Open source databases such as MySQL\cite{mysql}
and PostgreSQL\cite{postgres} currently do not support this
methodology. Parallel databases generally do not require a shared
data repository or filesystem.

Parallel database techniques have been used to build a scalable
geospatial database system\cite{paradise,cs-paradise}. Data is spread
between computers using round-robin, hash, or spatial partitioning. Because
the data is able to be distributed between multiple computers, the
processing is able to scale to larger datasets.

When a query is processed across the database, a thread is created
for each fragment of the data. Thus as the data grows larger, the
processing capabilities of the system also increase. If a particular
processing operation requires relatively less computation for each
data record this is fine. However, after the amount of computation per
data record increases beyond a certain point, which is dependent on the
speed of the machine used, the processing operation can be sped up by
utilizing more processors. Major factors in determining how much data
should be processed on each machine, and therefore how the data should
be spread between machines, are memory, computation, and communication
overhead to move the data and computation to another machine. The ratio
of computation to memory and commutation requirements is often referred
to as grain size. Coarser grained processes have more computation per
data record, while finer grained processes have little computation for
each data record.

Databases excel at working with indexed data while allowing multiple
users to interact with the data in a concurrently safe manner through
the use of atomic transactions. The requirements placed upon database
systems to handle these situations slow down computations that don't
utilize indexes or work on an entire dataset at once. The processing
operations this research examines do not require these restrictions,
and as such a more efficient system can be created.

Using databases can also limit the reusability of computer resources
to complete other processes. For example, a process could benefit from
utilizing more processors, but the disks on those database nodes could
already be fully utilized, thus making them unable to accommodate the
computation as it is directly tied to data storage. This is only really
an issue when trying to fully utilize hardware resources for different
purposes.

Many universities and research institutions already have significant
investment in compute clusters. These clusters are groups of computer
linked together with high speed network interconnects and high performance
parallel filesystems such as Lustre\cite{lustre}. By separating compute
and storage resources at the cost of a high speed network, compute
clusters are able to separate computation from data storage.  %TODO:
Compare to SAN approaches

Parallel filesystems alleviate the problems of separating the data from
the computer where the processing will be executed by spreading files
across multiple network connected fileservers allowing access that is
sometimes faster than utilizing a computer's local disk for storage
while also enabling processing to spread across the available compute
resources based entirely on the process' grain size.

\textbf{Paradise}

\section{Parallel GRASS}

\textbf{Other converted programs?}

\section{MRGIS MapReduce GIS}
