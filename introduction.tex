\chapter{INTRODUCTION}

% GIS processing is important, but data grows and computation time is too long

Geographic Information Systems (GIS) were designed to model aspects of
the world around us. From roads to temperature, GIS data can be used to
represent a large range of real-world objects, allowing for sophisticated
analysis and processing. 

GIS analysis and simulation are used to investigate and understand the
environment around us. A common use of GIS data is found in the GPS based
car navigation systems in common use today. City planners will use GIS
data in applications such as population growth models, land use planning,
and traffic management.

% Data growth (with examples) leads to long runtime or inability to
% process due to memory or processor limitations.

The amount of data to be processed increases as populations grow,
communities become more complex, or the size of the processing area
grows. In the year 2000, 1.2 million parcels of land were listed in the
9,224 square miles of Maricopa County, Arizona. Each parcel of land is
represented as a georeferenced polygon along with various attributes such
as a parcel id, ownership information, and zoning codes. Parcels of land
is just one set of data that is kept for Maricopa County. Other datasets
include roadways, railways, rivers, schools, voting districts, etc.

As the data grows, so does the processing time required to perform
simulation and analysis processes. Furthermore, modern analysis
for problems like climate change use more than one dataset; thereby
increasing the computational requirements even more.

When the data required to complete GIS processing grows beyond the memory
available to a single processor, the processing method must be adapted
to fit within that limitation. A common method is to not load the entire
dataset into memory, but to read it off disk as needed. This method
works well if the data is only needed once, as reading from disk is slow.

One application, which is looked at in more detail later, associates
businesses with parcels of land (the data was geocoded differently). The
algorithm is quite simple: for each business, find the nearest parcel of
land with a compatible zoning code. In Maricopa County in the year 2000,
there were 34,302 businesses and 1,218,130 parcels of land. While these
particular datasets fit into memory today, they did not just a few years
ago. Given increased parcel density, or a larger area of land, the memory
capabilities of a standard computer are quickly reached. While there are
specially made computers with extraordinarily large amounts of memory,
they are also extraordinarily expensive.

In addition to memory limitations, the processor also limits the
processing that can be done. In this case 41,784,295,260 comparisons
between businesses and parcels is made. If a computer is able to make one
million comparisons per second, the processing will take approximately 11
hours, 37 minutes. A factor increase in speed to ten million comparisons
per second reduces the time to 1 hour 10 minutes. If only there was a
single computer that would perform 100 billion of these comparisons per
second, then the processing would be done in less than half a second!

As an infinitely fast computer with infinite memory does not exist,
more effort is required to perform this processing in a reasonable time.

\section{Parallel GIS Processing}

Using multiple interconnected computers to complete the required GIS
processing allows for increased memory capabilities along with increased
computation power. Processing algorithms must be reworked to allow for
this collaboration between computers.

% Overview, full definitions in requirements section

Programming for multiple machines is not the easiest of tasks. A
common paradigm for parallel programming is Single Program, Multiple
Data\cite{spmd} (SPMD), which uses a single program that is run on all
the computers included in the parallel computation where each instance
of the program operates on different data, for example a different set of
businesses. This paradigm simplifies parallel algorithm complexity while
providing enough power to increase memory capability and computation
power.

% data distribution - record split, size split, geographically split - quads, by number of records, how to handle overlaps?

The first step in working with an SPMD program is splitting the data. GIS
data can be split in several different ways. The specific data splitting
method used is dependent on what data is needed on what machine. The data
used in this thesis is a set of records; each record contains a geometry
with its associated attributes. One method that can be used is to evenly
distribute the records among the participating machines. Another method
takes into account the varying size of geometries in memory by splitting
the data up by size while taking into account record boundaries. Another
class of data distribution is to geographically split up the dataset,
for instance into quadrants with each machine having responsibility
for one or more quadrants. This method is more complicated in the setup
required and the exceptions that need to be handled such as how to handle
geometries that span more than one quadrant.

After the data is distributed, the processing methodology often needs
to be adjusted because access to the full dataset at once is no longer
possible. Combined with the data distribution, these two additions are
needed for a parallel implementation, but not the serial case. This is
the overhead required to take advantage of more than one computer to
complete the processing.

Parallel performance is measured through speedup:

\begin{equation}
\label{speedup}
\mbox{speedup}(n) = \mbox{time}(1)/\mbox{time}(n)
\end{equation}

Speedup compares the execution time of the process on $n$ processors to
the execution time on $1$ processor. Ideal speedup is $n$.

The scalability of a parallel solution can be seen by graphing speedup
by number of processors used. The best realistic case is to have linear
scalability, meaning that speedup is directly proportional to the number
of processing elements used.

% Programmability/Flexibility

\section {Alternative Approaches to Parallel GIS Processing}

% Thesis: implement and evaluate.
This thesis implements and evaluates two parallel, dataset centric
approaches to processing large geospatial datasets on clusters with the
intent of gaining insight into which approach is more suitable for GIS
processing, and why. The first approach uses the map-reduce paradigm. The
second uses message passing, which is currently the standard approach
for programming clusters. This thesis uses existing implementations of
both these paradigms, focusing instead on their applicability for GIS
processing. Furthermore, the geospatial operations required to handle
GIS processing have been distilled into libraries that conform to the
Open Geospatial Consortium's Simple Features\cite{ogc-sfs} standard. By
applying data parallel programming methods to GIS processing, both these
approaches create a fairly easy environment to program in while providing
significant speedup and scaleup.

% Map/Reduce with Hadoop

The first approach, called hadoopGIS, uses the open source
Hadoop map/reduce framework.  Hadoop is based on Google's
MapReduce\cite{mapreduce}. Map reduce defines a two-phase method to
working with data. The first phase, map, applies a function to every
record in a data set. The map function can output one or more key-value
pairs. Map is an inherently parallel process, as no record is need to
process any other record.

After the map phase, the generated key-value pairs are aggregated by
key and passed to reduce processes, one reduce process per key. There
are generally many fewer reduce operations as compared to map
operations. Reduce operations are inherently serial, as the operation
must have access to all the key-value pairs associated with the key
being processed.

HadoopGIS simply adds a GIS data type to Hadoop, thus enabling for GIS
processing. Geospatial processing is provided through the Java Topology
Suite\cite{jts} (JTS).

% Traditional Cluster: MPI

The second approach, called clusterGIS, uses the MPI\cite{mpi} message
passing library.  Message passing works by creating a process, called
a task, on each participating processor core. Each task operates
independently and is assigned a unique address. Tasks can collaborate
with each other by passing messages.

ClusterGIS is simply library of functions that employ MPI and the
GEOS\cite{geos} library to handle common situations such as loading and
saving data.

% What has been done/what is lacking. What is needed to constitute a good
% approach. Design of the two approaches. How to evaluate approaches.
% Evaluation. Conclusion.

The rest of this thesis is organized as follows: Chapter 2 explores
related efforts in GIS processing. Chapter 3 then defines the specific
requirements needed for a good parallel GIS processing engine. Chapter
4 details the design choices for HadoopGIS and ClusterGIS. Chapter 5
defines a set of tests and list individual results. Chapter 6 evaluates
the two implementations by comparing performance results against the
requirements defined in chapter 3. Chapter 8 summarizes conclusions
drawn from the evaluation.
