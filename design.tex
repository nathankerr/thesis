\chapter{DESIGN}
% \addtocontents{toc}{\protect{\addtolength\topmargin{40pt}\addtolength\textheight{-40pt}}}

To discover the differences between using message passing and map reduce
as approaches for parallel GIS processing, this thesis implements two
environments for manipulating GIS data. The first approach, hadoopGIS,
is based the Hadoop map-reduce framework. The second, clusterGIS,
uses MPI. Both implementations build on these existing technologies
and utilize standards compliant geospatial libraries. The main work is
combining the underlying parallel technology with geospatial processing
capabilities in a way that works for that paradigm.

One point of simplification made for both implementations is supporting
only one file format. Both hadoopGIS and clusterGIS use CSV formatted data
with geospatial data stored in the Well Known Text (WKT)\cite{ogc-sfs}
format. HadoopGIS adds an additional file which stores the column names,
one on each line. ClusterGIS just uses column numbers.

\section{HadoopGIS}

HadoopGIS provides a Hadoop native GIS datatype. This allows for GIS data
to be used in Hadoop just like any other supported format. Geospatial
processing support is provided through the Java Topology Suite\cite{jts}
(JTS). Adding a new datatype to the Hadoop environment required overcoming
three data transfer boundaries: file to map, map to reduce, and reduce to file.
Figure \ref{hadoopgis-flow} shows how the components of HadoopGIS convert and pass
data between the map and reduce phases.

\begin{figure}
\label{hadoopgis-flow}
\includegraphics{hadoopGIS-flow.eps}
\caption{HadoopGIS Data Flow}
\end{figure}

The first gap to overcome is getting data into the mappers. Hadoop
uses two classes in addition to the core GIS class to load data
from HDFS blocks. The process starts with GISInputFormat which uses
GISRecordReader. GISRecordReader is responsible for extracting the
records from a file block. In this case, GISRecordReader wraps the
Hadoop supplied LineRecordReader, which manages to solve the problem
of connecting lines in a file split between blocks. In this phase the
geospatial data is converted from WKT to a Geometry object provided by
the Java Topology Suite.

To bridge the gap between mappers and reducers, Hadoop created
an interface called Writable. The GIS class implements writable by
providing functions that serialize the object state into a byte stream,
and reconstitute an object from that byte stream.

The last gap to cross is taking data from the reducers and putting
it back on HDFS. The process here is nearly a mirror image of loading
data, except that the data is being written. The process starts with
GISOutputFormat which utilizes GISRecordWriter. GISRecordWrite converts
the GIS object back into CSV format and sends the resulting byte stream
through the supplied DataOutputStream.

This design builds upon the basic architecture of Hadoop and adds as
little as possible to get a GIS datatype to work in the environment. The
user of this new functionality has access to the full power of both
Hadoop's task and data management which allows for parallel processing,
and the capabilities of a JTS geometry object which implements all the
standard geospatial operations. All of this is done for the user by them
stating that the input data should use the GISInputFormat and outputted
data uses the GISOutputFormat.

This enhancement does not address Hadoop's architecture. This means the
use of a secondary dataset is still problematic. The map function only
is provided with one record. The framework expects most computation that
requires access to more than just one record to be accomplished in the
reduce phase. There is provision, however, to load extra data when a
mapper is created. These limitation will be discussed further in the
experimental setup and results section of this thesis.

\section{ClusterGIS}

ClusterGIS makes use of MPI to manage communication between multiple
tasks and the GEOS library to provide the required geospatial operations.

The main task allotted to the clusterGIS library is to load one
or more geospatial datasets in such a way that the GIS records are
distributed between participating tasks. MPI tasks are grouped into
communicators. By passing a specific communicator to a helper function,
the tasks participating in the processing done by that function can be
limited. MPI provides a default communication, MPI\_COMM\_WORLD, which
contains all the tasks controlled by the MPI runtime.

\begin{figure}
\label{clusterGIS-flow}
\includegraphics{clusterGIS-flow.eps}
\caption{ClusterGIS Data Flow}
\end{figure}
\addtocontents{lof}{\protect{\vspace{-12pt}}}

Datasets can be loaded into participating tasks from a file by calling
one of the clusterGIS load functions. Two main load functions exist:
distributed and replicated. The replicated load function makes a copy
the dataset on each task. The distributed load function splits the
datasets's records among the participating tasks. The split is currently
done byte-wise, meaning that each task is responsible for the records
contained within a range of bytes in the source file. Records that overlap
these boundaries are handled by each task dropping the first partial
record and completed the final partial record. In this way no records
are lost and the splitting process only requires a single complete read
of the dataset with the addition of the overlapping sections.

Both the load functions take advantage of MPI-I/O. MPI-I/O is a collective
I/O interface which optimizes how the data in a file is read from disk
by communicating between the tasks participating in the collective
operation. As disks are slow, this collaboration allows for decreased
read time. MPI-I/O is also used for the write functions.

No matter if the load was distributed or replicated, the resulting local
dataset is stored as a linked list. Each node in the linked list has an
array containing the columns of the represented record. There is also a
pointer for the geometry of the record. After the load, the geometry has
not yet been created. ClusterGIS provides a function that will create
all the geometries for a dataset.

After the data is loaded and the geometries created, the user can now
proceed with the desired processing activities taking advantage of the
full power of both MPI and GEOS.

When the user is ready to save a dataset, the write functions of
clusterGIS are available. Like the load functions, the write functions
come in distributed and replicated varieties. The replicated write
function will write just one complete copy of the dataset out (each task
has its own copy, but only one will be written to disk). The distributed
write function writes all of the records for all of the participating
tasks into one file.

The main idea of clusterGIS is to provide a few essential library
functions that handle some of the basic, yet tricky, functions that
a parallel program must implement. With these provided functions, the
user can easily get to writing the more interesting and relevant parts
of the processing program.
